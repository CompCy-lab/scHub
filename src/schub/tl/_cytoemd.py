from typing import Optional, Union

try:
    from typing import Literal
except ImportError:
    from typing_extensions import Literal
import logging
import multiprocessing as mp
from functools import partial
from itertools import combinations

import numpy as np
import pandas as pd
import umap
from anndata import AnnData
from scanpy._utils import AnyRandom
from scanpy.tools._utils import _choose_representation
from scipy.sparse import issparse
from scipy.stats import wasserstein_distance
from sklearn.manifold import MDS, TSNE, Isomap
from tqdm import tqdm

from schub.utils import _get_rep_columns

logger = logging.getLogger(__name__)


# embedding methods
EMBED_METHOD_TYPE = Literal["umap", "tsne", "mds", "isomap"]
manifold_learning_methods = {"umap": umap.UMAP, "tsne": TSNE, "mds": MDS, "isomap": Isomap}


def cytoemd(
    adata: AnnData,
    partition_key: str,
    n_pcs: Optional[int] = None,
    use_rep: Optional[str] = None,
    n_components: int = 2,
    embedding_method: EMBED_METHOD_TYPE = "umap",
    bins: Union[str, int] = "auto",
    norm=None,
    use_pyemd: bool = False,
    random_state: AnyRandom = 42,
    n_jobs: int = -1,
    key_added: Optional[str] = None,
    copy=False,
    **embedding_kwargs,
) -> Optional[AnnData]:
    """CytoEMD model for detecting and visualizing between-sample variation :cite:`yi2022cytoemd`

    CytoEMD generates the sample embedding in a multi-sample single-cell dataset in relation to phenotype by
    computing earth mover's distance (EMD) between two sets of cells from two samples.

    Parameters
    ----------
    adata
        Annotated data of type `anndata.AnnData`
    partition_key
        Column key in the field of `adata.obs` indicating the sample ids
    n_pcs
        Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`
    use_rep
        Use the indicated representation. `'X'` or any key for `.obsm` is valid.
        If `None`, the representation is chosen automatically:
        For `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used.
        If 'X_pca' is not present, it's computed with default parameters.
    n_components
        Number of components for generating sample embeddings
    embedding_method
        Method for embedding, e.g., "umap", "tsne", and "mds"
    bins
        Number of bins for discretizing the data distributions
    norm
        Normalization method for aggregating distance across markers
    use_pyemd
        Whether to use the python implementation of EMD
    random_state
        A random seed which supports an `int`, `None` and `np.random.RandomState`
    n_jobs
        Number of cpus to use in the EMD calculation
    key_added
        If not specified, the results are stored in `.uns['cytoemd']`.
        If specified, the results are stored in `.uns[key_added+'_cytoemd']`.
    copy
        Return a copy instead of writing the results into `adata`.
    **embedding_kwargs
        Additional keyword arguments for the embedding method.

    Returns
    -------
    Depending on `copy`, updates or returns `adata` with the following fields.

    **cytoemd** or **{key_added}_cytoemd**: `adata.uns` field
        Embeddings of the samples and distances between samples generated by CytoEMD
    """
    adata = adata.copy() if copy else adata
    if adata.is_view:
        adata._init_as_actual(adata.copy())

    if key_added is None:
        key_added = "cytoemd"
    else:
        key_added = key_added + "_cytoemd"

    adata.uns[key_added] = {}

    cytoemd_dict = adata.uns[key_added]

    cytoemd_dict["partition_key"] = partition_key
    cytoemd_dict["params"] = {
        "bins": bins,
        "norm": norm,
        "method": embedding_method,
    }
    cytoemd_dict["random_state"] = random_state

    X = _choose_representation(adata, use_rep=use_rep, n_pcs=n_pcs, silent=True)
    if issparse(X):
        X = X.toarray()
    if use_rep is not None:
        cytoemd_dict["params"]["use_rep"] = use_rep
    if n_pcs is not None:
        cytoemd_dict["params"]["n_pcs"] = n_pcs

    # save the data into a pandas dataframe
    columns = _get_rep_columns(adata, use_rep=use_rep, n_pcs=n_pcs)
    df_partition = pd.DataFrame(X, columns=columns)
    df_partition[partition_key] = adata.obs[partition_key].tolist()

    sample_names, data_list = [], []
    for sample_name, df in df_partition.groupby(by=partition_key, sort=False):
        sample_names.append(sample_name)
        data_list.append(df.drop(columns=[partition_key]).to_numpy())

    if n_jobs == -1:
        n_jobs = max(mp.cpu_count() // 2, 1)  # heuristically set jobs as half of total cpu cores
    # compute emd distance each pair of samples
    sample_emb_distance = calculate_emd_distance(
        data_list=data_list,
        n_jobs=n_jobs,
        norm=norm,
        use_pyemd=use_pyemd,
    )

    # generate sample embeddings
    kwargs = {"dissimilarity": "precomputed"} if embedding_method == "MDS" else {"metric": "precomputed"}
    kwargs.update(embedding_kwargs)
    embeddings = manifold_learning_methods[embedding_method](
        n_components=n_components,
        random_state=random_state,
        **kwargs,
    ).fit_transform(sample_emb_distance)

    cytoemd_dict["emd"] = sample_emb_distance
    cytoemd_dict["X_emd"] = pd.DataFrame(
        embeddings, index=sample_names, columns=[f"EMD_{i}" for i in range(n_components)]
    )

    return adata if copy else None


def calculate_emd_distance(
    data_list: list[np.ndarray],
    n_jobs: int,
    bins: Union[str, int] = "auto",
    norm=None,
    use_pyemd: bool = True,
):
    """Compute the earth mover's distance between each pair of set of data (np.ndarray)"""
    num_sample = len(data_list)
    num_markers = data_list[0].shape[1]
    dtype = data_list[0].dtype
    idx_list = list(range(num_sample))

    distance_tensor = np.zeros((num_markers, num_sample, num_sample), dtype=dtype)
    bin_edges, min_flows = {}, {}
    num_pairs = num_sample * (num_sample - 1) // 2

    # set the multiprocessing pool size
    pool = mp.Pool(n_jobs)
    pair_distances = pool.imap(
        partial(emd_between_samples, use_pyemd=use_pyemd, bins=bins),
        zip(combinations(idx_list, r=2), combinations(data_list, r=2)),
    )

    count = 0
    with tqdm(range(num_pairs)) as t:
        for (i, j, dis_vec), bg, mf in pair_distances:
            distance_tensor[:, i, j] = dis_vec
            distance_tensor[:, j, i] = dis_vec
            if use_pyemd:
                bin_edges[(i, j)] = bg
                min_flows[(i, j)] = mf
            count += 1
            t.update()

    pool.close()
    pool.join()

    # check results
    assert count == num_pairs, "the processed number != data number, some computations are missed."
    # compute distance matrix
    distance_matrix = np.linalg.norm(distance_tensor, ord=norm, axis=0, keepdims=False)

    return distance_matrix


def emd_between_samples(
    _input,
    use_pyemd: bool = False,
    bins: Union[str, int] = "auto",
):
    i, j = _input[0]
    mat1, mat2 = _input[1]
    n_var = mat1.shape[1]

    dis_vec = np.zeros((n_var,), dtype=mat1.dtype)
    bin_edges, min_flows = [], []
    for k in range(n_var):
        dis_vec[k], be, mf = _emd_between_arrays(mat1[:, k], mat2[:, k], use_pyemd=use_pyemd, bins=bins)
        bin_edges.append(be)
        min_flows.append(mf)
    return (i, j, dis_vec), bin_edges, min_flows


def _emd_between_arrays(
    first_array: np.ndarray,
    second_array: np.ndarray,
    use_pyemd: bool = False,
    normalized: bool = True,
    bins: Union[int, str] = "auto",
    bin_range=None,
):
    """Compute Earth Mover's Distance between two 1-d `np.array`"""
    first_array = np.array(first_array)
    second_array = np.array(second_array)

    if not (first_array.size > 0 and second_array.size > 0):
        raise ValueError("input arrays cannot be empty.")
    if bin_range is None:
        bin_range = (min(np.min(first_array), np.min(second_array)), max(np.max(first_array), np.max(second_array)))

    bins = np.histogram_bin_edges(
        np.concatenate([first_array, second_array]),
        range=bin_range,
        bins=bins,
    )
    # compute histograms
    first_histogram, bin_edges = np.histogram(first_array, range=bin_range, bins=bins)
    second_histogram, _ = np.histogram(second_array, range=bin_range, bins=bins)

    if normalized:
        first_histogram = first_histogram / first_histogram.sum()
        second_histogram = second_histogram / second_histogram.sum()
    # compute the distance between the center of each bin
    bin_locations = np.mean([bin_edges[:-1], bin_edges[1:]], axis=0)

    if use_pyemd:
        try:
            import pyemd
        except ImportError as e:
            raise ImportError("Please install the pyemd package via `pip install --user pyemd`") from e

        first_histogram = first_histogram.astype(np.float64)
        second_histogram = second_histogram.astype(np.float64)
        bin_length = len(bin_locations)
        distance_matrix = np.abs(np.repeat(bin_locations, bin_length) - np.tile(bin_locations, bin_length))
        distance_matrix = distance_matrix.reshape(bin_length, bin_length)
        emd_distance, min_flow = pyemd.emd_with_flow(
            first_histogram,
            second_histogram,
            distance_matrix,
        )

        return emd_distance, bin_edges, min_flow
    else:
        return (wasserstein_distance(bin_locations, bin_locations, first_histogram, second_histogram), None, None)
